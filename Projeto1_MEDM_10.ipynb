{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49333279",
   "metadata": {},
   "source": [
    "# Métodos Estatísticos em Data Mining\n",
    "### Projeto 1\n",
    "\n",
    "##### Grupo 10:\n",
    "- 88174 Marisa Pereira \n",
    "- 89616 Beatriz Silva  \n",
    "- 89629 João Batista \n",
    "- 89640 Tomás Freire\n",
    "\n",
    "\n",
    "April 25st, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51618cc6",
   "metadata": {},
   "source": [
    "# 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f794e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install.packages(\"mice\")\n",
    "#install.packages(\"corrplot\")\n",
    "#install.packages(\"ggplot2\")\n",
    "#install.packages(\"psych\")\n",
    "#install.packages(\"MASS\")\n",
    "#install.packages(\"comprehenr\")\n",
    "#install.packages(\"rpart\")\n",
    "#install.packages(\"rpart.plot\")\n",
    "#install.packages(\"caTools\")\n",
    "#install.packages(\"neuralnet\")\n",
    "#install.packages(\"logisticPCA\")\n",
    "#install.packages(\"mlr\") \n",
    "#install.packages(\"imbalance\") \n",
    "#install.packages(\"caret\")\n",
    "#install.packages(\"sats\")\n",
    "#install.packages(\"dplyr\")\n",
    "#install.packages(\"tidyverse\")\n",
    "#install.packages(\"funModeling\")\n",
    "#install.packages(\"Hmisc\")\n",
    "#install.packages(\"factoextra\")\n",
    "#install.packages(\"ggplot2\")\n",
    "#install.packages(\"grid\")\n",
    "#install.packages(\"devtools\")\n",
    "#install.packages(\"factoextra\")\n",
    "#install.packages(\"e1071\")\n",
    "#install.packages(\"caret\")\n",
    "#install.packages(\"pROC\")\n",
    "#install.packages(\"base\")\n",
    "#install.packages(\"MLmetrics\")\n",
    "#install.packages(\"nnet\")\n",
    "#install.packages(\"rpart\")\n",
    "#install.packages(\"rpart.plot\")\n",
    "#install.packages(\"klaR\")\n",
    "#install.packages(\"imbalance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3c4914",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"stats\")\n",
    "library(\"dplyr\")\n",
    "library(\"tidyverse\")\n",
    "library(\"funModeling\")\n",
    "library(\"Hmisc\")\n",
    "library(\"ggplot2\")\n",
    "library(\"grid\")\n",
    "library(\"factoextra\")\n",
    "library(\"devtools\")\n",
    "library(\"plyr\")\n",
    "library(\"factoextra\")\n",
    "library(\"e1071\")\n",
    "library(\"caret\")\n",
    "library(\"pROC\")\n",
    "library(\"base\")\n",
    "library(\"MLmetrics\")\n",
    "library(\"nnet\")\n",
    "library(\"rpart\")\n",
    "library(\"rpart.plot\")\n",
    "library(\"klaR\")\n",
    "library(\"imbalance\")\n",
    "library(\"MASS\")\n",
    "library(\"comprehenr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbbc4ce",
   "metadata": {},
   "source": [
    "# 2. Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6921d92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- read.csv(\"Myocardial-infarction-complications-Database.csv\")\n",
    "#tirar as variaveis que nao usamos no nosso problema\n",
    "df <- df[c(1:93,96:100,103,106:112,119)]\n",
    "\n",
    "#Remove all dimensions with more that 35% of missing values: (NA_KB; NOT_NA_KB; LID_KB; IBS_NASL;S_AD_KBRIG; D_AD_KBRIG; KFK_BLOOD)\n",
    "data <- df[-c(8,94,95,96,89,35,36)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92a8526",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac160b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary\n",
    "summary(df)\n",
    "#descriptive statistics\n",
    "round(describe(df),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10709351",
   "metadata": {},
   "source": [
    "## 3.1 Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347f48c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dealing with missing values:\n",
    "library(\"mice\")\n",
    "\n",
    "#Applying Predictive Mean Matching 5 times and choosing one of them\n",
    "imp <- mice(data[,-c(1)], m = 5, method = \"pmm\",seed=20); # Impute missing values\n",
    "data_imp <- complete(imp,2);\n",
    "data_imp <- cbind(data[,c(1)],data_imp);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1230b5bd",
   "metadata": {},
   "source": [
    "## 3.2 Correlation\n",
    "#### Conclusion: \n",
    "- Variables S_AD_ORIT and D_AD_ORIT have a correlation of 0.86, so here we Remove the first one;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0119939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables S_AD_ORIT and D_AD_ORIT have a correlation of 0.86, so here we Remove the first one.\n",
    "data_sem_corr <- data_imp[,-c(34)];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d38620",
   "metadata": {},
   "source": [
    "## 3.3 Creating Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865aafe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tirar as variaveis continuas\n",
    "data_sem_continuas <-  data_sem_corr[,-c(1,2,34,80,82,83,84,85,86,99)]\n",
    "\n",
    "#passar as variaveis para \"factor\":\n",
    "for (i in 1:length(data_sem_continuas)) {\n",
    "    #data$Region <- as.factor(data$Region)\n",
    "    data_sem_continuas[,i] <- as.factor(data_sem_continuas[,i])\n",
    "    \n",
    "    }\n",
    "\n",
    "#criar dummy variables:\n",
    "library(\"mlr\")\n",
    "\n",
    "data_com_dummies <- createDummyFeatures(data_sem_continuas, method = \"reference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688b92f3",
   "metadata": {},
   "source": [
    "## 3.4 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ab9825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fazer logistic PCA:\n",
    "library(\"logisticPCA\")\n",
    "\n",
    "\n",
    "dimension = 25\n",
    "#logpca_cv.25<-cv.lpca(data_com_dummies, ks = dimension, ms = 1:13)\n",
    "#plot(logpca_cv.25)\n",
    "logpca_model.25<-logisticPCA(data_com_dummies, k = dimension, m = 11)\n",
    "#logpca_model.25\n",
    "\n",
    "\n",
    "#o \"logpca_model.25$PCs\", que tem a informação, é estranho... vamos transformar isto numa matriz de jeito\n",
    "data_25 <- matrix(0, nrow = 1700, ncol = 25)\n",
    "for (i in 1:25) {\n",
    "    #data$Region <- as.factor(data$Region)\n",
    "    data_25[,i] <- logpca_model.25$PCs[,i]\n",
    "    \n",
    "    }\n",
    "\n",
    "#repor as variaveis continuas e a de resposta:\n",
    "\n",
    "data_final <- cbind(data_sem_corr[,c(1,2)], data_25)\n",
    "data_final <- cbind(data_final, data_sem_corr[,c(34,80,82,83,84,85,86,99)])\n",
    "\n",
    "\n",
    "#se as variaveis nao tivessem os mesmos nomes dava erro so...\n",
    "colnames(data_final)[2] <- \"AGE\"\n",
    "colnames(data_final)[3] <- \"X1\"\n",
    "colnames(data_final)[4] <- \"X2\"\n",
    "colnames(data_final)[5] <- \"X3\"\n",
    "colnames(data_final)[6] <- \"X4\"\n",
    "colnames(data_final)[7] <- \"X5\"\n",
    "colnames(data_final)[8] <- \"X6\"\n",
    "colnames(data_final)[9] <- \"X7\"\n",
    "colnames(data_final)[10] <- \"X8\"\n",
    "colnames(data_final)[11] <- \"X9\"\n",
    "colnames(data_final)[12] <- \"X10\"\n",
    "colnames(data_final)[13] <- \"X11\"\n",
    "colnames(data_final)[14] <- \"X12\"\n",
    "colnames(data_final)[15] <- \"X13\"\n",
    "colnames(data_final)[16] <- \"X14\"\n",
    "colnames(data_final)[17] <- \"X15\"\n",
    "colnames(data_final)[18] <- \"X16\"\n",
    "colnames(data_final)[19] <- \"X17\"\n",
    "colnames(data_final)[20] <- \"X18\"\n",
    "colnames(data_final)[21] <- \"X19\"\n",
    "colnames(data_final)[22] <- \"X20\"\n",
    "colnames(data_final)[23] <- \"X21\"\n",
    "colnames(data_final)[24] <- \"X22\"\n",
    "colnames(data_final)[25] <- \"X23\"\n",
    "colnames(data_final)[26] <- \"X24\"\n",
    "colnames(data_final)[27] <- \"X25\"\n",
    "\n",
    "#é preciso mudar o nome da variavel resposta par \"Class\" para o oversample funcionar\n",
    "data_final$Class <- data_sem_corr[,c(99)]\n",
    "data_final <- data_final[,-c(35)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00973ec",
   "metadata": {},
   "source": [
    "## 3.4 Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcfff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fazer oversample:\n",
    "#o site diz: MWMOTE is an extension of the original SMOTE algorithm. It assigns higher weight to borderline instances, \n",
    "#undersized minority clusters and examples near the borderline of the two classes.\n",
    "\n",
    "newMWMOTE <- mwmote(data_final[,-c(1)], numInstances = 300)\n",
    "data_oversample <- rbind(data_final[,-c(1)],newMWMOTE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754f36f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_final[,35]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84980008",
   "metadata": {},
   "source": [
    "### Proof that dimension 25 is better and with m=11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c86128e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dimension = 25\n",
    "#logpca_cv.26<-cv.lpca(data_com_dummies, ks = dimension, ms = 1:13)\n",
    "#plot(logpca_cv.26)\n",
    "#logpca_model.26<-logisticPCA(data_com_dummies, k = dimension, m = which.min(logpca_cv.26))\n",
    "#logpca_model.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15242e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dimension = 24\n",
    "#logpca_cv.26<-cv.lpca(data_com_dummies, ks = dimension, ms = 1:13)\n",
    "#plot(logpca_cv.26)\n",
    "#logpca_model.26<-logisticPCA(data_com_dummies, k = dimension, m = which.min(logpca_cv.26))\n",
    "\n",
    "#logpca_model.26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48db2125",
   "metadata": {},
   "source": [
    "# 4. Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3a4b09",
   "metadata": {},
   "source": [
    "## 4.1 Final Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be53795",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final<-data_final[,-c(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7e80bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames(data_final)[34] <- \"resposta\"\n",
    "\n",
    "\n",
    "data_final$resposta<- as.factor(data_final$resposta)\n",
    "\n",
    "set.seed(5968)\n",
    "indxTrain <- createDataPartition(y = data_final$resposta ,p = 0.9,list = FALSE)\n",
    "data.train <- data_final[indxTrain,]\n",
    "data.test <- data_final[-indxTrain,] \n",
    "# Setting levels for both training and test data\n",
    "levels(data.train$resposta) <- make.names(levels(factor(data.train$resposta)))\n",
    "levels(data.test$resposta) <- make.names(levels(factor(data.test$resposta)))\n",
    "data.test$resposta <- factor(data.test$resposta , levels=rev(levels(data.test$resposta)))\n",
    "data.train$resposta <- factor(data.train$resposta , levels=rev(levels(data.train$resposta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5473ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = caret::trainControl(method = 'cv',\n",
    "                        number = 10,\n",
    "                        classProbs = TRUE,\n",
    "                        summaryFunction = prSummary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149a094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_nn = caret::trainControl(method = 'cv',\n",
    "                        number = 10,\n",
    "                        classProbs = TRUE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9a54ef",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819ada48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelnb<-caret::train(resposta~. , data = data.train, method = 'nb',trControl = x,  \n",
    "                tuneLength = 10, metric = \"F\")\n",
    "modelnb\n",
    "plot(modelnb)\n",
    "\n",
    "#confusion matrix and statistics for the model \n",
    "test_pred_nb <- predict(modelnb, newdata = data.test)\n",
    "confusionMatrix(test_pred_nb, data.test$resposta, mode=\"everything\", positive=\"X1\")\n",
    "\n",
    "roc.multi_nb<-multiclass.roc(data.test$resposta,as.numeric(test_pred_nb))\n",
    "roc.multi_nb$auc\n",
    "#rs <- roc.multi[['rocs']]\n",
    "#plot.roc(rs[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05edc01e",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67079878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-NN classifier\n",
    "n_vizinhos = c(1,3,5,7,9,11,13,15,17,19,21,23)\n",
    "modelknn<- caret::train(resposta~. , data = data.train, method = 'knn',\n",
    "                          tuneGrid   = expand.grid(k = n_vizinhos),\n",
    "                          trControl = x,  \n",
    "                          tuneLength = 10,\n",
    "                       metric = \"F\")\n",
    "# Summary of model 1(no standardised data)\n",
    "modelknn\n",
    "plot(modelknn)\n",
    "\n",
    "#confusion matrix and statistics for the model \n",
    "test_pred_knn <- predict(modelknn, newdata = data.test)\n",
    "confusionMatrix(test_pred_knn, data.test$resposta, mode=\"everything\", positive=\"X1\")\n",
    "roc.multi_knn<-multiclass.roc(data.test$resposta,as.numeric(test_pred_knn))\n",
    "roc.multi_knn$auc\n",
    "#rs <- roc.multi[['rocs']]\n",
    "#plot.roc(rs[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2739dec",
   "metadata": {},
   "source": [
    "## Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3bfcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression\n",
    "modelmlr <- caret::train(resposta~. , data = data.train, method = 'multinom',\n",
    "                 trControl = x,  \n",
    "                 tuneLength = 10,\n",
    "                metric = \"F\")\n",
    "#modelmlr\n",
    "plot(modelmlr)\n",
    "\n",
    "#confusion matrix and statistics for the model \n",
    "test_pred_blr <- predict(modelmlr, newdata = data.test)\n",
    "confusionMatrix(test_pred_blr, data.test$resposta,mode=\"everything\", positive=\"X1\")\n",
    "roc.multi_blr<-multiclass.roc(data.test$resposta,as.numeric(test_pred_blr))\n",
    "roc.multi_blr$auc\n",
    "#rs <- roc.multi[['rocs']]\n",
    "#plot.roc(rs[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6c487f",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d43de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelnn <- caret::train(resposta~. , data = data.train, method = 'nnet',trControl = x_nn,  \n",
    "                tuneLength = 10)\n",
    "#modelnn\n",
    "plot(modelnn)\n",
    "test_pred_nn <- predict(modelnn, newdata = data.test)\n",
    "confusionMatrix(test_pred_nn, data.test$resposta, mode=\"everything\", positive=\"X1\")\n",
    "roc.multi_nn<-multiclass.roc(data.test$resposta,as.numeric(test_pred_nn))\n",
    "roc.multi_nn$auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429aa85a",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599286ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "modellda <- caret::train(resposta~.,\n",
    "                      method     = \"lda\",\n",
    "                      trControl  = x_nn,\n",
    "                      data       = data.train)\n",
    "\n",
    "test_pred_lda <- predict(modellda, newdata = data.test)\n",
    "confusionMatrix(test_pred_lda, data.test$resposta,mode=\"everything\", positive=\"X1\")\n",
    "roc.multi_lda<-multiclass.roc(data.test$resposta,as.numeric(test_pred_lda))\n",
    "roc.multi_lda$auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f76ab8",
   "metadata": {},
   "source": [
    "## LDA Cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f58b922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#função que treina o linear discriminant analises:\n",
    "library(\"MASS\")\n",
    "library(\"comprehenr\")\n",
    "\n",
    "LDA <- function(data,response){\n",
    "    \n",
    "data_aux <- data\n",
    "\n",
    "#function that trains the linear discriminator, with leave one out cross validation\n",
    "fit  <- lda(x = data_aux[,-c(response)],grouping = data_aux[,c(response)],CV=TRUE)\n",
    "\n",
    "#calculating the criteria, accuracy, recalls, precisions and F1-score\n",
    "print(\"confusion matrix: first collum -> are truly negative;  second line -> are classified as positive\")\n",
    "tt<-table(fit$class,data_aux[,c(response)]);print(tt)\n",
    "print(\"accuracy:\")\n",
    "acc<-sum(diag(tt))/sum(tt);print(acc)\n",
    "print(\"recalls:\")\n",
    "recalls <- to_vec(for(i in 1:2) if(TRUE) diag(tt)[i]/sum(tt[,i]));print(recalls)\n",
    "print(\"precisions:\")\n",
    "precisions  <- to_vec(for(i in 1:2) if(TRUE) diag(tt)[i]/sum(tt[i,]));print(precisions)\n",
    "print(\"F1_measures:\")\n",
    "F1_measure  <-to_vec(for(i in 1:2) if(TRUE) 2*recalls[i]*precisions[i]/(recalls[i]+precisions[i])  );print(F1_measure)\n",
    "print(\"Overall F1_measure:\")\n",
    "F1 <- mean(c(F1_measure));print(F1)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfcd427",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subtrair a média a todos os valores\n",
    "data_aux <- data_final[,-c(34)]\n",
    "\n",
    "nomes <- c()\n",
    "\n",
    "data_final_centered <- matrix(0, nrow = length(data_aux[,c(1)]), ncol = length(data_aux))\n",
    "for (i in 1:length(data_aux)) {\n",
    "    mean_aux = mean(data_aux[,c(i)])\n",
    "    for (j in 1:length(data_aux[,1])){\n",
    "        \n",
    "        data_final_centered[j,i] = data_aux[j,i] - mean_aux \n",
    "        }\n",
    "    }\n",
    "#fazer os cross products\n",
    "\n",
    "data_aux <- data_final_centered\n",
    "data_final_cross <- matrix(0, nrow = length(data_aux[,1]), ncol = length(data_aux[1,]) * (length(data_aux[1,])+1) / 2)\n",
    "for (i in 1:length(data_aux[1,])) {\n",
    "    \n",
    "    for (j in i:length(data_aux[1,])){\n",
    "        tamanho_aux = length(data_aux[1,]) + 1\n",
    "        \n",
    "        m <-  (tamanho_aux-i+1):tamanho_aux; #sum(m) \n",
    "        \n",
    "        n = sum(m) - tamanho_aux + j - i + 1\n",
    "        \n",
    "        data_final_cross[,n] = data_aux[,i] * data_aux[,j]\n",
    "        \n",
    "        nomes <- c(nomes, paste(colnames( data_final[,-c(34)])[i], colnames( data_final[,-c(34)])[j]))\n",
    "    }\n",
    "}\n",
    "colnames(data_final_cross) <- nomes\n",
    "data_final_cross <- cbind(data_final_cross, data_final[,c(34)])\n",
    "colnames(data_final_cross)[562] <- \"resposta_cross\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6215f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA(data_final_cross,562)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456b5b6f",
   "metadata": {},
   "source": [
    "## QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d68d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelqda <- caret::train(resposta~.,\n",
    "                      method     = \"qda\",\n",
    "                      trControl  = x_nn,\n",
    "                      data       = data.train)\n",
    "\n",
    "test_pred_qda <- predict(modelqda, newdata = data.test)\n",
    "confusionMatrix(test_pred_qda, data.test$resposta,mode=\"everything\", positive=\"X1\")\n",
    "roc.multi_qda<-multiclass.roc(data.test$resposta,as.numeric(test_pred_qda))\n",
    "roc.multi_qda$auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e2210f",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0e53d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsvm<- caret::train(resposta~. , data = data.train, method = 'svmRadial',\n",
    "                 trControl = x, preProcess = c(\"center\",\"scale\"),  \n",
    "                 tuneLength = 10)\n",
    "#modelsvm\n",
    "plot(modelsvm)\n",
    "\n",
    "#confusion matrix and statistics for the model \n",
    "test_pred_svm <- predict(modelsvm, newdata = data.test)\n",
    "confusionMatrix(test_pred_svm, data.test$resposta,mode=\"everything\", positive=\"X1\")\n",
    "roc.multi_svm<-multiclass.roc(data.test$resposta,as.numeric(test_pred_svm))\n",
    "roc.multi_svm$auc\n",
    "#rs <- roc.multi[['rocs']]\n",
    "#plot.roc(rs[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132b710d",
   "metadata": {},
   "source": [
    "## 4.2 Oversample Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b37c8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames(data_oversample)[34] <- \"resposta\"\n",
    "\n",
    "set.seed(2021)\n",
    "data_oversample$resposta<- as.factor(data_oversample$resposta)\n",
    "\n",
    "indxTrain <- createDataPartition(y = data_oversample$resposta ,p = 0.90,list = FALSE)\n",
    "data.train_over <- data_oversample[indxTrain,]\n",
    "data.test_over <- data_oversample[-indxTrain,] \n",
    "\n",
    "# Setting levels for both training and test data\n",
    "levels(data.train_over$resposta) <- make.names(levels(factor(data.train_over$resposta)))\n",
    "levels(data.test_over$resposta) <- make.names(levels(factor(data.test_over$resposta)))\n",
    "data.test_over$resposta <- factor(data.test_over$resposta , levels=rev(levels(data.test_over$resposta)))\n",
    "data.train_over$resposta <- factor(data.train_over$resposta , levels=rev(levels(data.train_over$resposta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e5b9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = caret::trainControl(method = 'cv',\n",
    "                        number = 10,\n",
    "                        classProbs = TRUE,\n",
    "                        summaryFunction = prSummary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1603d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_nn = caret::trainControl(method = 'cv',\n",
    "                        number = 10,\n",
    "                        classProbs = TRUE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84082da4",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250b9ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelnb_over <- caret::train(resposta~. , data = data.train_over, method = 'nb',trControl = x,  \n",
    "                tuneLength = 10, metric=\"F\")\n",
    "modelnb_over\n",
    "plot(modelnb_over)\n",
    "\n",
    "#confusion matrix and statistics for the model \n",
    "test_pred_nb_over <- predict(modelnb_over, newdata = data.test_over)\n",
    "confusionMatrix(test_pred_nb_over, data.test_over$resposta, mode=\"everything\", positive=\"X1\")\n",
    "roc.multi_nb_over<-multiclass.roc(data.test_over$resposta,as.numeric(test_pred_nb_over))\n",
    "roc.multi_nb_over$auc\n",
    "#rs <- roc.multi[['rocs']]\n",
    "#plot.roc(rs[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d09eceb",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d2488",
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-NN classifier\n",
    "n_vizinhos = c(1,3,5,7,9,11,13,15,17,19,21,23)\n",
    "modelknn_over<- caret::train(resposta~. , data = data.train_over, method = 'knn',\n",
    "                          tuneGrid   = expand.grid(k = n_vizinhos),\n",
    "                          trControl = x,  \n",
    "                          tuneLength = 10,\n",
    "                        metric=\"F\")\n",
    "# Summary of model 1(no standardised data)\n",
    "modelknn_over\n",
    "plot(modelknn_over)\n",
    "\n",
    "#confusion matrix and statistics for the model \n",
    "test_pred_knn_over <- predict(modelknn_over, newdata = data.test_over)\n",
    "confusionMatrix(test_pred_knn_over, data.test_over$resposta, mode=\"everything\", positive=\"X1\")\n",
    "roc.multi_knn_over<-multiclass.roc(data.test_over$resposta,as.numeric(test_pred_knn_over))\n",
    "roc.multi_knn_over$auc\n",
    "#rs <- roc.multi[['rocs']]\n",
    "#plot.roc(rs[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5a2978",
   "metadata": {},
   "source": [
    "## Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f90d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelmlr<- caret::train(resposta~. , data = data.train_over, method = 'multinom',\n",
    "                 trControl = x,  \n",
    "                 tuneLength = 10,\n",
    "                       metric = \"F\")\n",
    "#modelmlr\n",
    "plot(modelmlr)\n",
    "\n",
    "#confusion matrix and statistics for the model \n",
    "test_pred_blr_over <- predict(modelmlr, newdata = data.test_over)\n",
    "confusionMatrix(test_pred_blr_over, data.test_over$resposta,mode=\"everything\", positive=\"X1\")\n",
    "roc.multi_blr_over<-multiclass.roc(data.test_over$resposta,as.numeric(test_pred_blr_over))\n",
    "roc.multi_blr_over$auc\n",
    "#rs <- roc.multi[['rocs']]\n",
    "#plot.roc(rs[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bca90fe",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54efe672",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelnn_over <- caret::train(resposta~. , data = data.train_over, method = 'nnet',trControl = x_nn,  \n",
    "                tuneLength = 10)\n",
    "#modelnn_over\n",
    "plot(modelnn_over)\n",
    "test_pred_nn_over <- predict(modelnn_over, newdata = data.test_over)\n",
    "confusionMatrix(test_pred_nn_over, data.test_over$resposta, mode=\"everything\", positive=\"X1\")\n",
    "roc.multi_nn_over<-multiclass.roc(data.test_over$resposta,as.numeric(test_pred_nn_over))\n",
    "roc.multi_nn_over$auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06147956",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae2e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "modellda_over <- caret::train(resposta~.,\n",
    "                      method     = \"lda\",\n",
    "                      trControl  = x_nn,\n",
    "                      data       = data.train_over)\n",
    "\n",
    "test_pred_lda_over <- predict(modellda_over, newdata = data.test_over)\n",
    "confusionMatrix(test_pred_lda_over, data.test_over$resposta,mode=\"everything\", positive=\"X1\")\n",
    "roc.multi_lda_over<-multiclass.roc(data.test_over$resposta,as.numeric(test_pred_lda_over))\n",
    "roc.multi_lda_over$auc\n",
    "#rs <- roc.multi_lda_over[['rocs']]\n",
    "#plot.roc(rs[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d2f0ca",
   "metadata": {},
   "source": [
    "## LDA Cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a864b9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subtrair a média a todos os valores\n",
    "data_aux <- data_oversample[,-c(34)]\n",
    "\n",
    "data_oversample_centered <- matrix(0, nrow = length(data_aux[,c(1)]), ncol = length(data_aux))\n",
    "\n",
    "nomes <- c()\n",
    "\n",
    "for (i in 1:length(data_aux)) { \n",
    "    mean_aux = mean(data_aux[,c(i)])\n",
    "    \n",
    "    for (j in 1:length(data_aux[,1])){  \n",
    "        data_oversample_centered[j,i] = data_aux[j,i] - mean_aux \n",
    "        }\n",
    "    }\n",
    "#fazer os cross products\n",
    "\n",
    "data_aux <- data_oversample_centered\n",
    "data_oversample_cross <- matrix(0, nrow = length(data_aux[,1]), ncol = length(data_aux[1,]) * (length(data_aux[1,])+1) / 2)\n",
    "for (i in 1:length(data_aux[1,])) {\n",
    "    for (j in i:length(data_aux[1,])){\n",
    "        tamanho_aux = length(data_aux[1,]) + 1\n",
    "        \n",
    "        m <-  (tamanho_aux-i+1):tamanho_aux; #sum(m) \n",
    "        \n",
    "        n = sum(m) - tamanho_aux + j - i + 1\n",
    "        \n",
    "        data_oversample_cross[,n] = data_aux[,i] * data_aux[,j]\n",
    "\n",
    "        nomes <- c(nomes, paste(colnames( data_oversample[,-c(34)])[i], colnames( data_oversample[,-c(34)])[j]))\n",
    "\n",
    "    }\n",
    "}\n",
    "colnames(data_oversample_cross) <- nomes\n",
    "data_oversample_cross <- cbind(data_oversample_cross, data_oversample[,c(34)])\n",
    "colnames(data_oversample_cross)[562] <- \"resposta_cross\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7489648",
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA(data_oversample_cross,562)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436c0860",
   "metadata": {},
   "source": [
    "## QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d326a827",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelqda_over <- caret::train(resposta~.,\n",
    "                      method     = \"qda\",\n",
    "                      trControl  = x_nn,\n",
    "                      data       = data.train_over)\n",
    "\n",
    "test_pred_qda_over <- predict(modelqda_over, newdata = data.test_over)\n",
    "confusionMatrix(test_pred_qda_over, data.test_over$resposta,mode=\"everything\", positive=\"X1\")\n",
    "roc.multi_qda_over<-multiclass.roc(data.test_over$resposta,as.numeric(test_pred_qda_over))\n",
    "roc.multi_qda_over$auc\n",
    "#rs <- roc.multi_qda_over[['rocs']]\n",
    "#plot.roc(rs[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6935cca5",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e55f0b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelsvm_over <- caret::train(resposta~. , data = data.train_over, method = 'svmRadial',\n",
    "                 trControl = x, preProcess = c(\"center\",\"scale\"),  \n",
    "                 tuneLength = 10,\n",
    "                       metric = \"F\")\n",
    "#modelsvm\n",
    "plot(modelsvm_over)\n",
    "\n",
    "#confusion matrix and statistics for the model \n",
    "test_pred_svm_over <- predict(modelsvm_over, newdata = data.test_over)\n",
    "confusionMatrix(test_pred_svm_over, data.test_over$resposta,mode=\"everything\", positive=\"X1\")\n",
    "roc.multi_svm_over<-multiclass.roc(data.test_over$resposta,as.numeric(test_pred_svm_over))\n",
    "roc.multi_svm_over$auc\n",
    "#rs <- roc.multi[['rocs']]\n",
    "#plot.roc(rs[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c97941",
   "metadata": {},
   "source": [
    "## 4.3 Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892509ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(\"rpart\")\n",
    "library(\"rpart.plot\")\n",
    "library(\"caTools\")\n",
    "tree <- function(data,response){\n",
    "    \n",
    "data_aux <- data\n",
    "\n",
    "#we will add the measure of every simulation and then average in the end\n",
    "#this code initializes the variables that will keep the added measures.\n",
    "tt_tree_aux <- table(c(0,1), c(0,1)) - table(c(0,1), c(0,1))\n",
    "acc_tree_aux <- 0\n",
    "recalls_tree_aux <- c(0,0)\n",
    "precisions_tree_aux  <- c(0,0)\n",
    "F1_measure_tree_aux  <- c(0,0)\n",
    "F1_tree_aux <- 0\n",
    "\n",
    "#this cycle will train a tree 20 times and then average the criteria\n",
    "number_of_cycles <- 20\n",
    "for (i in 1:number_of_cycles) {\n",
    "  \n",
    "  #split the data into training set and testing set\n",
    "  spl = sample.split(data_aux, SplitRatio = 0.90)\n",
    "  train = subset(data_aux, spl==TRUE)\n",
    "  test = subset(data_aux, spl==FALSE)\n",
    "  \n",
    "  #training the tree using the training set\n",
    "  fit_tree <- rpart(train[,c(response)]~., data = train[,-c(response)], method = 'class');fit_tree\n",
    "\n",
    "  #predictions on the testing set\n",
    "  predictions_tree <- predict(fit_tree, newdata = test[,-c(response)], type = 'class')\n",
    "  \n",
    "  #calculating the criteria, accuracy, recalls, precisions and F1-score\n",
    "  tt_tree <- table(predictions_tree, test[,c(response)])\n",
    "  acc_tree <- sum(diag(tt_tree))/sum(tt_tree)\n",
    "  recalls_tree <- to_vec(for(i in 1:2) if(TRUE) diag(tt_tree)[i]/sum(tt_tree[,i]))\n",
    "  precisions_tree  <- to_vec(for(i in 1:2) if(TRUE) diag(tt_tree)[i]/sum(tt_tree[i,]))\n",
    "  F1_measure_tree  <- to_vec(for(i in 1:2) if(TRUE) 2*recalls_tree[i]*precisions_tree[i]/(recalls_tree[i]+precisions_tree[i])  )\n",
    "  F1_tree <- mean(c(F1_measure_tree))\n",
    "  \n",
    "  \n",
    "  #This is to add the measure with previous simulations, in the end the average will be made\n",
    "  tt_tree_aux <- tt_tree_aux + tt_tree\n",
    "  acc_tree_aux <- acc_tree_aux + acc_tree\n",
    "  recalls_tree_aux <- recalls_tree_aux + recalls_tree\n",
    "  precisions_tree_aux  <- precisions_tree_aux + precisions_tree\n",
    "  F1_measure_tree_aux  <- F1_measure_tree_aux + F1_measure_tree\n",
    "  F1_tree_aux <- F1_tree_aux + F1_tree\n",
    "}\n",
    "#this plots the last calculated tree\n",
    "rpart.plot(fit_tree,box.palette = colorRampPalette(c(\"#F55118\",\"#FF9933\",\"#FFFFFF\",\"#66CCCC\",\"#298DF7\"))(50))\n",
    "\n",
    "#finaly, the criteria are averaged out\n",
    "print(\"confusion matrix: first collum -> are truly positive;  second line -> are classified as negative\")\n",
    "tt_tree_final <- tt_tree_aux/number_of_cycles;print(tt_tree_final)\n",
    "print(\"accuracy:\")\n",
    "acc_tree_final <- acc_tree_aux/number_of_cycles;print(acc_tree_final)\n",
    "print(\"recalls:\")  \n",
    "recalls_tree_final <- recalls_tree_aux/number_of_cycles;print(recalls_tree_final)\n",
    "print(\"precisions:\")\n",
    "precisions_tree_final  <- precisions_tree_aux/number_of_cycles;print(precisions_tree_final)\n",
    "print(\"F1_measures:\")\n",
    "F1_measure_tree_final  <- F1_measure_tree_aux/number_of_cycles;print(F1_measure_tree_final)\n",
    "print(\"Overall F1_measure:\")\n",
    "F1_tree_final <- F1_tree_aux/number_of_cycles;\n",
    "print(F1_tree_final)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08560cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree(data_final,34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32074536",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree(data_oversample,34)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
